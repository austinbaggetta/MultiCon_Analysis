{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austinbaggetta/.conda/envs/calcium/lib/python3.10/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.2, the latest is 0.5.3.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pingouin as pg\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from os.path import join as pjoin\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import pearsonr, spearmanr, zscore, wilcoxon\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "import circletrack_neural as ctn\n",
    "import circletrack_behavior as ctb\n",
    "import pca_ica as ica\n",
    "import plotting_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../EnsembleRemodeling_Resubmission/circletrack_data'\n",
    "mouse_list = ['mc03', 'mc06', 'mc07', 'mc09', 'mc11']   \n",
    "session_dict = {'mc03': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc06': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc07': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc09': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc11': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal']}\n",
    "cohort_number = 'cohort1'\n",
    "session_length = '30min'\n",
    "# ## Loop through all mice\n",
    "# for mouse in mouse_list:\n",
    "#     dpath = pjoin(path, 'Results/{}/'.format(mouse))\n",
    "#     session_dates = os.listdir(dpath)\n",
    "#     session_dates.sort()\n",
    "#     for i, date in enumerate(session_dates):\n",
    "#         ctn.minian_to_netcdf(path, mouse, date, session_id = session_dict[mouse][i], cohort_number = cohort_number, session_length = session_length,\n",
    "#                              sampling_rate = 1/15, down_sample_factor = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a list of sessions for easy plotting later and for changing column order\n",
    "session_list = ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal']\n",
    "## Create session_id dictionary\n",
    "session_dict = {'mc03': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc06': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc07': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc09': ['Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal'],\n",
    "                'mc11': ['Training1', 'Training2', 'Training3', 'Training4', 'Reversal1', 'Reversal2', 'Reversal3', 'Reversal4', 'Training_Reversal']}\n",
    "## Set path variables\n",
    "ensemble_path = '../../EnsembleRemodeling_Resubmission/circletrack_data/assemblies'\n",
    "behavior_path = '../../EnsembleRemodeling_Resubmission/circletrack_data/'  \n",
    "figure_path = '../../EnsembleRemodeling_Resubmission/circletrack_data/python_analysis/progress_figures/cohort1'\n",
    "## Create mouse list\n",
    "mouse_list = ['mc03', 'mc06', 'mc07', 'mc09', 'mc11']             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../EnsembleRemodeling_Resubmission/circletrack_data/keys.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m## Loop through mouse list\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m mouse \u001b[39min\u001b[39;00m mouse_list:\n\u001b[0;32m----> 7\u001b[0m     sessions \u001b[39m=\u001b[39m ctn\u001b[39m.\u001b[39;49mimport_mouse_neural_data(behavior_path, mouse, key_file \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mkeys.yml\u001b[39;49m\u001b[39m'\u001b[39;49m, session \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m30min\u001b[39;49m\u001b[39m'\u001b[39;49m, neural_type \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mspikes\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m     cell_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m session \u001b[39min\u001b[39;00m sessions:\n",
      "File \u001b[0;32m/media/caishuman/csstorage3/Austin/CircleTrack/CircleTrackAnalysis/EnsembleRemodeling_Resubmission/../circletrack_neural.py:300\u001b[0m, in \u001b[0;36mimport_mouse_neural_data\u001b[0;34m(path, mouse, key_file, session, neural_type, plot_frame_usage)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m## Load keys\u001b[39;00m\n\u001b[1;32m    299\u001b[0m key_path \u001b[39m=\u001b[39m pjoin(path, key_file)\n\u001b[0;32m--> 300\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(key_path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m stream:\n\u001b[1;32m    301\u001b[0m     data_loaded \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39msafe_load(stream)\n\u001b[1;32m    302\u001b[0m \u001b[39m## Select keys for a specific mouse\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../EnsembleRemodeling_Resubmission/circletrack_data/keys.yml'"
     ]
    }
   ],
   "source": [
    "## Number of neurons across sessions\n",
    "## Set mouse list\n",
    "mouse_list = ['mc03', 'mc06', 'mc07']\n",
    "mouse_neural = {}\n",
    "## Loop through mouse list\n",
    "for mouse in mouse_list:\n",
    "    sessions = ctn.import_mouse_neural_data(behavior_path, mouse, key_file = 'keys.yml', session = '30min', neural_type = 'spikes')\n",
    "    cell_dict = {}\n",
    "    for session in sessions:\n",
    "        cell_dict[session] = len(sessions[session].unit_id)\n",
    "    mouse_neural[mouse] = cell_dict\n",
    "fig = pf.custom_graph_template(title = 'Cells per Session', x_title = 'Session', y_title = 'Number of Cells')\n",
    "for mouse in mouse_neural:\n",
    "    plot_data = pd.DataFrame(mouse_neural[mouse], index = [0])\n",
    "    if mouse == 'mc03':\n",
    "        plot_data.insert(0, 'Reversal2', np.nan)\n",
    "        plot_data.insert(1, 'Reversal3', np.nan)\n",
    "    plot_data = plot_data[session_list]\n",
    "    fig.add_trace(go.Scatter(x = session_list, y = plot_data.iloc[0, :], mode = 'lines', line_color = 'grey', line_width = 0.5, opacity = 0.5, name = mouse, showlegend = False))\n",
    "fig.show()\n",
    "fig.write_image('progress_figures/cells_across_session.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot number of ensembles across all sessions\n",
    "ensemble_num_df = pd.DataFrame()\n",
    "mouse_name = []\n",
    "for i, mouse in enumerate(mouse_num_ensembles):\n",
    "    mouse_name.append(mouse)\n",
    "    df = pd.DataFrame(mouse_num_ensembles[mouse], index = [i])\n",
    "    ensemble_num_df = pd.concat([ensemble_num_df, df])\n",
    "ensemble_num_df = ensemble_num_df[session_list]\n",
    "## Calculate avg num of ensembles per session\n",
    "avg = ensemble_num_df.mean()\n",
    "## Plot data\n",
    "fig = pf.custom_graph_template(title = 'Ensembles Across Sessions', x_title = '', y_title = 'Number of Ensembles', width = 500, height = 500)\n",
    "fig.add_trace(go.Scatter(x = session_list, y = avg, marker = dict(color = 'turquoise'), showlegend = False))\n",
    "## Plot individual mice\n",
    "for mouse in mouse_num_ensembles:\n",
    "    fig.add_trace(go.Scatter(x = session_list, y = pd.Series(mouse_num_ensembles[mouse]), mode = 'lines', line_color = 'grey', opacity = 0.5, line_width = 0.5, showlegend = False, name = mouse))\n",
    "fig.show()\n",
    "fig.write_image('progress_figures/ensembles_across_sessions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set mouse list, x_bin_size, and across_time\n",
    "mouse_list = ['mc03', 'mc06', 'mc07', 'mc09']\n",
    "across_time = True\n",
    "x_bin_size = 5\n",
    "## Create empty dictionaries\n",
    "mouse_trends = {}\n",
    "mouse_binned_activations = {}\n",
    "mouse_slopes = {}\n",
    "mouse_taus = {}\n",
    "mouse_ensembles = {}\n",
    "mouse_num_ensembles = {}\n",
    "## Loop through each mouse\n",
    "for mouse in tqdm(mouse_list):\n",
    "    ## saved ensemble data path\n",
    "    spath = pjoin(ensemble_path, mouse)\n",
    "    ## load in behavior data across all sessions\n",
    "    if not across_time:\n",
    "        mouse_behavior = ctb.import_mouse_behavior_data(behavior_path, mouse, key_file = 'behavior_keys.yml', session = '30min')\n",
    "    ## Create empty dictionaries to store output\n",
    "    determined_trends = {}\n",
    "    binned_activations_dict = {}\n",
    "    slopes_dict = {}\n",
    "    tau_dict = {}\n",
    "    num_ensembles = {}\n",
    "    ## Load assemblies\n",
    "    for session in session_dict[mouse]:\n",
    "        ## Load a specific session's behavior data\n",
    "        if not across_time:\n",
    "            aligned_behavior = mouse_behavior[session]\n",
    "            ## Get which timestamps are part of which trial for the aligned behavior data\n",
    "            trials = ctb.get_trials(aligned_behavior, shift_factor = (np.pi / 2), angle_type = 'radians', counterclockwise = True)\n",
    "        ## Load a specific session's assemblies\n",
    "        assemblies = ica.load_session_assemblies(mouse, spath = spath, session_id = session)\n",
    "        act = assemblies.activations.values\n",
    "        ## Save the number of identified ensembles by PCA/ICA\n",
    "        num_ensembles[session] = act.shape[0]\n",
    "        if across_time:\n",
    "          trends, binned_activations, slopes, tau = ica.define_ensemble_trends_across_time(act, z_threshold = None, x_bin_size = x_bin_size, analysis_type = 'max', zscored = True, alpha = 'sidak')  \n",
    "        else:\n",
    "            ## Define ensemble trends across trials to determine if activation strength is increasing/decreasing across the session\n",
    "            trends, binned_activations, slopes, tau = ica.define_ensemble_trends_across_trials(act, aligned_behavior, trials, trial_type = 'forward', z_threshold = None)\n",
    "        ## Save to dictionaries\n",
    "        determined_trends[session] = trends\n",
    "        binned_activations_dict[session] = binned_activations\n",
    "        slopes_dict[session] = slopes\n",
    "        tau_dict[session] = tau\n",
    "    ## Determine the proportion of ensembles that are increasing, decreasing, or have no trend based on their activation strength across time\n",
    "    proportion_dict = ica.calculate_proportions_ensembles(determined_trends)\n",
    "    ## Save to mouse dictionaries before looping to the next mouse\n",
    "    mouse_trends[mouse] = proportion_dict\n",
    "    mouse_binned_activations[mouse] = binned_activations_dict\n",
    "    mouse_slopes[mouse] = slopes_dict\n",
    "    mouse_ensembles[mouse] = determined_trends\n",
    "    mouse_taus[mouse] = tau_dict\n",
    "    mouse_num_ensembles[mouse] = num_ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot peak activation of a fading ensemble\n",
    "activations = mouse_binned_activations['mc09']['Reversal1']\n",
    "ensemble_number = 5\n",
    "fig = pf.plot_activation_strength(activations, ensemble_number = ensemble_number, figure_path = figure_path, x_bin_size = x_bin_size,\n",
    "                                  title = 'Fading Ensemble', y_title = 'Max Z Score', x_title = 'Time (s)', \n",
    "                                  file_name = 'max_strength_fading_{}bins.png'.format(x_bin_size), marker_color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot peak activation of an increasing ensemble\n",
    "activations = mouse_binned_activations['mc09']['Reversal1']\n",
    "ensemble_number = 28\n",
    "fig = pf.plot_activation_strength(activations, ensemble_number = ensemble_number, figure_path = figure_path, x_bin_size = x_bin_size,\n",
    "                                  title = 'Increasing Ensemble', y_title = 'Max Z Score', x_title = 'Time (s)', \n",
    "                                  file_name = 'max_strength_increasing_{}bins.png'.format(x_bin_size), marker_color = 'turquoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot peak activation of a no-trend ensemble\n",
    "activations = mouse_binned_activations['mc09']['Reversal1']\n",
    "ensemble_number = 1\n",
    "fig = pf.plot_activation_strength(activations, ensemble_number = ensemble_number, figure_path = figure_path, x_bin_size = x_bin_size,\n",
    "                                  title = 'No Trend Ensemble', y_title = 'Max Z Score', x_title = 'Time (s)', \n",
    "                                  file_name = 'max_strength_notrend_{}bins.png'.format(x_bin_size), marker_color = 'darkgrey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get proportion decreasing values\n",
    "prop_decreasing_T4 = []\n",
    "prop_decreasing_R1 = []\n",
    "for key in mouse_trends:\n",
    "    prop_decreasing_T4.append(mouse_trends[key]['Training4']['prop_decreasing'])\n",
    "    prop_decreasing_R1.append(mouse_trends[key]['Reversal1']['prop_decreasing'])\n",
    "prop_df = pd.DataFrame({'Training4': prop_decreasing_T4, 'Reversal1': prop_decreasing_R1})\n",
    "## Plot prop_df\n",
    "x = ['Training4', 'Reversal1']\n",
    "avgs = [prop_df.Training4.mean(), prop_df.Reversal1.mean()]\n",
    "sem = [prop_df.Training4.sem(), prop_df.Reversal1.sem()]\n",
    "fig = go.Figure(data = go.Bar(x = x, y = avgs, error_y = dict(type = 'data', array = sem), showlegend = False))\n",
    "for row in prop_df.index:\n",
    "    data = prop_df.loc[row]\n",
    "    fig.add_trace(go.Scatter(x = x, y = [data.Training4, data.Reversal1], mode = 'lines + markers', showlegend = False,\n",
    "                             line = dict(width = 1)))\n",
    "fig.update_layout(template = 'simple_white', width = 500, height = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Fading Ensembles',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(title = 'Proportion Fading Ensembles')\n",
    "fig.update_traces(marker_color = 'red', marker_line_color = 'black', marker_line_width = 2)\n",
    "fig.show()\n",
    "fig.write_image('progress_figures/binned_by_15seconds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get proportion fading ensembles for last day, since some mice went back to Training reward port contingencies\n",
    "training_group = []\n",
    "reversal_group = []\n",
    "mice_training = ['mc06', 'mc09', 'mc11']\n",
    "mice_reversal = ['mc03', 'mc07']\n",
    "for mouse in mice_training:\n",
    "    training_group.append(mouse_trends[mouse]['Training_Reversal']['prop_decreasing'])\n",
    "for mouse in mice_reversal:\n",
    "    reversal_group.append(mouse_trends[mouse]['Training_Reversal']['prop_decreasing'])\n",
    "## Add NaN to make mice_reversal same length as mice_training\n",
    "reversal_group.append(np.nan)\n",
    "## Create dataframe\n",
    "df = pd.DataFrame({'Training_Contingency': training_group, 'Reversal_Contingency': reversal_group})\n",
    "avgs = [df.Training_Contingency.mean(), df.Reversal_Contingency.mean()]\n",
    "sem = [df.Training_Contingency.sem(), df.Reversal_Contingency.sem()]\n",
    "## Plot figure\n",
    "x = ['Training Contingency', 'Reversal Contingency']\n",
    "fig = go.Figure(data = go.Bar(x = x, y = avgs, error_y = dict(type = 'data', array = sem)))\n",
    "fig.update_layout(template = 'simple_white', width = 500, height = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Fading Ensembles',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(title = 'Proportion Fading Ensembles')\n",
    "fig.update_traces(marker_color = 'red', marker_line_color = 'black', marker_line_width = 2)\n",
    "fig.show()\n",
    "fig.write_image('progress_figures/training_contingency_15seconds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at average number of fading ensembles across all training sessions and across all reversal sessions\n",
    "trainings = ['Training1', 'Training2', 'Training3', 'Training4']\n",
    "reversals = ['Reversal1', 'Reversal2', 'Reversal3', 'Reversal4']\n",
    "prop_dec_training = []\n",
    "prop_dec_reversal = []\n",
    "mouse_list = []\n",
    "for mouse in mouse_trends:\n",
    "    for session in trainings:\n",
    "        prop_dec_training.append(mouse_trends[mouse][session]['prop_decreasing'])\n",
    "        mouse_list.append(mouse)\n",
    "    ## Because mc03 doesn't have Reversal2 or Reversal3 due to miniscope issues, add only Reversal1 and Reversal4 manually\n",
    "    if mouse == 'mc03':\n",
    "            prop_dec_reversal.append(mouse_trends[mouse][reversals[0]]['prop_decreasing'])\n",
    "            prop_dec_reversal.append(mouse_trends[mouse][reversals[3]]['prop_decreasing'])\n",
    "            ## Add NaN to prop_dec_reversal to make it same length as prop_dec_training\n",
    "            prop_dec_reversal.append(np.nan)\n",
    "            prop_dec_reversal.append(np.nan)\n",
    "    else:\n",
    "        for reverse in reversals:\n",
    "            prop_dec_reversal.append(mouse_trends[mouse][reverse]['prop_decreasing'])\n",
    "## Create dataframe\n",
    "df = pd.DataFrame({'Mouse': mouse_list, 'Trainings': prop_dec_training, 'Reversals': prop_dec_reversal})\n",
    "## melt df for plotting\n",
    "df_melt = pd.melt(df, id_vars = ['Mouse'], value_vars = ['Trainings', 'Reversals'], var_name = 'session')\n",
    "## Averages by mouse\n",
    "avgs = df.groupby(['Mouse'], as_index = False).mean(numeric_only = True)\n",
    "sem = df.groupby(['Mouse'], as_index = False).sem()\n",
    "## Plot groups\n",
    "pf.plot_across_groups(df_melt, groupby = 'Mouse', separateby = 'session', plot_var = 'value', colors = 'red', title = 'Fading Ensembles Across Each Epoch', y_title = 'Proportion Fading Ensembles',\n",
    "                      save_path = '/media/caishuman/csstorage3/Austin/CircleTrack/EnsembleRemodeling_Resubmission/CircleTrack_Data/python_analysis/progress_figures/fading_across_all_15seconds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot three ensembles with their members colored \n",
    "fig = pf.stem_plot(assemblies['patterns'][1], member_color = 'turquoise', size = 3)\n",
    "fig1 = pf.stem_plot(assemblies['patterns'][4], member_color = 'turquoise', size = 3)\n",
    "fig2 = pf.stem_plot(assemblies['patterns'][7], member_color = 'turquoise', size = 3)\n",
    "fig.update_layout(height = 300, width = 500)\n",
    "fig1.update_layout(height = 300, width = 500)\n",
    "fig2.update_layout(height = 300, width = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Ensemble Membership',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(range = [-0.55, 0.55], tickvals=[0.4, 0.2, 0, -0.2, -0.4])\n",
    "fig1.update_yaxes(range = [-0.55, 0.55], tickvals=[0.4, 0.2, 0, -0.2, -0.4])\n",
    "fig2.update_yaxes(range = [-0.55, 0.55], tickvals=[0.4, 0.2, 0, -0.2, -0.4])\n",
    "fig.show()\n",
    "fig.write_image('progress_figures/ensemble_membership_top.png')\n",
    "fig1.show()\n",
    "fig1.write_image('progress_figures/ensemble_membership_one.png')\n",
    "fig2.show()\n",
    "fig2.write_image('progress_figures/ensemble_membership_two.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot fading ensembles across all sessions\n",
    "## Create empty dictionary\n",
    "trends_dict = {}\n",
    "## Loop through mouse_trends and extract the proportion of fading ensembles for each session (Training1, Training2, etc)\n",
    "for key in mouse_trends:\n",
    "    fading_ensembles = []\n",
    "    for session in mouse_trends[key]:\n",
    "        fading_ensembles.append(mouse_trends[key][session]['prop_decreasing'])\n",
    "    trends_dict[key] = fading_ensembles\n",
    "## Add in NaN values for days that are missing for mc03\n",
    "trends_dict['mc03'][5] = np.nan\n",
    "trends_dict['mc03'][6] = np.nan\n",
    "trends_dict['mc03'].append(0.0) ## value for proportion of fading ensembles on Reversal4\n",
    "trends_dict['mc03'].append(0.029411764705882353) ## value for proportion of fading ensembles on Training_Reversal\n",
    "## Plot values for each mouse\n",
    "fig = go.Figure()\n",
    "x_axis = session_list\n",
    "for key in trends_dict:\n",
    "    fig.add_trace(go.Scatter(x = x_axis, y = trends_dict[key], name = key))\n",
    "fig.update_layout(template = 'simple_white', height = 500, width = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Fading Ensemble Proportion Across Sessions',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(title = 'Proportion Fading Ensembles')\n",
    "fig.show()\n",
    "fig.write_image('progress_figures/fading_all_sessions_15seconds.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is to subset the neural data across FORWARD TRIALS and detect fading ensembles using trials to bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set mouse list, path, and z_thresh for binarization\n",
    "mouse_list = ['mc03', 'mc06', 'mc07', 'mc09', 'mc11'] \n",
    "across_time = False\n",
    "analysis_type = 'max'\n",
    "alpha_old = 0.05\n",
    "## Create empty dictionaries\n",
    "mouse_trends = {}\n",
    "mouse_binned_activations = {}\n",
    "mouse_slopes = {}\n",
    "mouse_taus = {}\n",
    "mouse_ensembles = {}\n",
    "mouse_trial_times = {}\n",
    "## Loop through each mouse\n",
    "for mouse in tqdm(mouse_list):\n",
    "    ## Create empty dictionaries to store output\n",
    "    determined_trends = {}\n",
    "    binned_activations_dict = {}\n",
    "    slopes_dict = {}\n",
    "    tau_dict = {}\n",
    "    trial_times = {}\n",
    "    ensemble_path = '../../EnsembleRemodeling_Resubmission/circletrack_data/assemblies'\n",
    "    behav_path = '../../EnsembleRemodeling_Resubmission/circletrack_data/output/behav'  \n",
    "    behav_path = pjoin(behav_path, '{}'.format(mouse))\n",
    "    ensemble_path = pjoin(ensemble_path, '{}'.format(mouse))\n",
    "    ## Load assemblies\n",
    "    for session in session_dict[mouse]:\n",
    "        ## Load specific session's assemblies\n",
    "        assemblies = ica.load_session_assemblies(mouse, ensemble_path, session)\n",
    "        ## Set activation values as act\n",
    "        act = assemblies.activations.values\n",
    "        ## Load a specific session's behavior data\n",
    "        if not across_time:\n",
    "            behav_file = pjoin(behav_path, '{}_{}.feat'.format(mouse, session))\n",
    "            behavior_df = pd.read_feather(behav_file)\n",
    "            aligned_behavior = ctb.align_behavior_frames(behavior_df, session='30min', sampling_rate=1/15)\n",
    "            ## Ensure that activations and aligned behavior are the same length\n",
    "            aligned_behavior = ica.align_activations_to_behavior(act, aligned_behavior)\n",
    "            ## Get which timestamps are part of which trial for the aligned behavior data\n",
    "            trials = aligned_behavior.trials\n",
    "            ## Get length of time for each trial\n",
    "            time_diff = []\n",
    "            for trial in np.unique(trials):\n",
    "                ## Subset aligned_behavior by a given trial\n",
    "                behavior = aligned_behavior.loc[trials == trial]\n",
    "                ## Get the first and last timestamp to determine the window\n",
    "                first_timestamp, last_timestamp = behavior.t.to_numpy()[0], behavior.t.to_numpy()[-1]\n",
    "                ## Convert from ms to s\n",
    "                first_timestamp = first_timestamp\n",
    "                last_timestamp = last_timestamp\n",
    "                ## Append to time_diff list\n",
    "                time_diff.append(last_timestamp - first_timestamp)\n",
    "            trial_times[session] = time_diff\n",
    "        ## This is where the data gets binned either by even time intervals or by trials\n",
    "        if across_time:\n",
    "          trends, binned_activations, slopes, tau = ica.define_ensemble_trends_across_time(act, z_threshold = None, x_bin_size = x_bin_size, analysis_type = analysis_type, \n",
    "                                                                                           zscored = True, alpha_old = alpha_old)  \n",
    "        else:\n",
    "            ## Define ensemble trends across trials to determine if activation strength is increasing/decreasing across the session\n",
    "            trends, binned_activations, slopes, tau = ica.define_ensemble_trends_across_trials(act, aligned_behavior, trials, trial_type = 'all', \n",
    "                                                                                               z_threshold = None, alpha_old = alpha_old, analysis_type = analysis_type)\n",
    "        ## Save to dictionaries\n",
    "        determined_trends[session] = trends\n",
    "        binned_activations_dict[session] = binned_activations\n",
    "        slopes_dict[session] = slopes\n",
    "        tau_dict[session] = tau\n",
    "    ## Determine the proportion of ensembles that are increasing, decreasing, or have no trend based on their activation strength across time\n",
    "    proportion_dict = ica.calculate_proportions_ensembles(determined_trends)\n",
    "    ## Save to mouse dictionaries before looping to the next mouse\n",
    "    mouse_trends[mouse] = proportion_dict\n",
    "    mouse_binned_activations[mouse] = binned_activations_dict\n",
    "    mouse_slopes[mouse] = slopes_dict\n",
    "    mouse_taus[mouse] = tau_dict\n",
    "    mouse_ensembles[mouse] = determined_trends\n",
    "    mouse_trial_times[mouse] = trial_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_df\n",
    "arg_mins = [np.abs(behavior_df['t'] - (t)).argmin() for t in time]\n",
    "lined_up_timeframes = np.array(behavior_df.loc[arg_mins, 'frame']) \n",
    "lined_up_timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = behavior_df.loc[behavior_df['water'] == True]\n",
    "reward_one, reward_two = np.unique(rewards['lick_port'])[0], np.unique(rewards['lick_port'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot peak activation of a fading ensemble\n",
    "activations = mouse_binned_activations['mc09']['Reversal1']\n",
    "ensemble_number = 1\n",
    "fig = pf.plot_activation_strength(activations, ensemble_number = ensemble_number, figure_path = figure_path, x_bin_size = None,\n",
    "                                  title = 'Fading Ensemble', y_title = 'Max Z Score', x_title = 'Trials', \n",
    "                                  file_name = 'max_strength_fading_forward_trials.png'.format(x_bin_size), marker_color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot peak activation of an increasing ensemble\n",
    "activations = mouse_binned_activations['mc09']['Reversal1']\n",
    "ensemble_number = 57\n",
    "fig = pf.plot_activation_strength(activations, ensemble_number = ensemble_number, figure_path = figure_path, x_bin_size = None,\n",
    "                                  title = 'Increasing Ensemble', y_title = 'Max Z Score', x_title = 'Trials', \n",
    "                                  file_name = 'max_strength_increasing_forward_trials.png'.format(x_bin_size), marker_color = 'turquoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot peak activation of a no-trend ensemble\n",
    "activations = mouse_binned_activations['mc09']['Reversal1']\n",
    "ensemble_number = 28\n",
    "fig = pf.plot_activation_strength(activations, ensemble_number = ensemble_number, figure_path = figure_path, x_bin_size = None,\n",
    "                                  title = 'No Trend Ensemble', y_title = 'Max Z Score', x_title = 'Trials', \n",
    "                                  file_name = 'max_strength_notrend_forward_trials.png'.format(x_bin_size), marker_color = 'darkgrey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get proportion decreasing values\n",
    "prop_decreasing_T4 = []\n",
    "prop_decreasing_R1 = []\n",
    "mouse_name = []\n",
    "for key in mouse_trends:\n",
    "    prop_decreasing_T4.append(mouse_trends[key]['Training4']['prop_decreasing'])\n",
    "    prop_decreasing_R1.append(mouse_trends[key]['Reversal1']['prop_decreasing'])\n",
    "    mouse_name.append(key)\n",
    "prop_df = pd.DataFrame({'Mouse': mouse_name, 'Training4': prop_decreasing_T4, 'Reversal1': prop_decreasing_R1})\n",
    "## Plot prop_df\n",
    "x = ['Training4', 'Reversal1']\n",
    "avgs = [prop_df.Training4.mean(), prop_df.Reversal1.mean()]\n",
    "sem = [prop_df.Training4.sem(), prop_df.Reversal1.sem()]\n",
    "fig = go.Figure(data = go.Bar(x = x, y = avgs, error_y = dict(type = 'data', array = sem), showlegend = False))\n",
    "for row in prop_df.index:\n",
    "    data = prop_df.loc[row]\n",
    "    fig.add_trace(go.Scatter(x = x, y = [data.Training4, data.Reversal1], mode = 'lines', line_color = 'grey', showlegend = False,\n",
    "                             line = dict(width = 1), name = prop_df.loc[row, 'Mouse']))\n",
    "fig.update_layout(template = 'simple_white', width = 500, height = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Fading Ensembles by Forward Trials',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(title = 'Proportion Fading Ensembles')\n",
    "fig.update_traces(marker_color = 'red', marker_line_color = 'black', marker_line_width = 2)\n",
    "fig.show()\n",
    "# fig.write_image(pjoin(figure_path, 'proportion_fading_trials_max.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon_result = wilcoxon(x = prop_df.Training4, y = prop_df.Reversal1, method = 'approx')\n",
    "wilcoxon_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get proportion fading ensembles for last day, since some mice went back to Training reward port contingencies\n",
    "training_group = []\n",
    "reversal_group = []\n",
    "mice_training = ['mc06', 'mc09']\n",
    "mice_reversal = ['mc03', 'mc07']\n",
    "for mouse in mice_training:\n",
    "    training_group.append(mouse_trends[mouse]['Training_Reversal']['prop_decreasing'])\n",
    "for mouse in mice_reversal:\n",
    "    reversal_group.append(mouse_trends[mouse]['Training_Reversal']['prop_decreasing'])\n",
    "## Create dataframe\n",
    "df = pd.DataFrame({'Training_Contingency': training_group, 'Reversal_Contingency': reversal_group})\n",
    "avgs = [df.Training_Contingency.mean(), df.Reversal_Contingency.mean()]\n",
    "sem = [df.Training_Contingency.sem(), df.Reversal_Contingency.sem()]\n",
    "## Plot figure\n",
    "x = ['Training Contingency', 'Reversal Contingency']\n",
    "fig = go.Figure(data = go.Bar(x = x, y = avgs, error_y = dict(type = 'data', array = sem)))\n",
    "fig.update_layout(template = 'simple_white', width = 500, height = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Fading Ensembles by Forward Trials',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(title = 'Proportion Fading Ensembles')\n",
    "fig.update_traces(marker_color = 'red', marker_line_color = 'black', marker_line_width = 2)\n",
    "fig.show()\n",
    "fig.write_image(pjoin(figure_path, 'proportion_fading_last_day_trials.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot fading ensembles across all sessions\n",
    "## Create empty dictionary\n",
    "trends_dict = {}\n",
    "## Loop through mouse_trends and extract the proportion of fading ensembles for each session (Training1, Training2, etc)\n",
    "for key in mouse_trends:\n",
    "    fading_ensembles = []\n",
    "    for session in mouse_trends[key]:\n",
    "        fading_ensembles.append(mouse_trends[key][session]['prop_decreasing'])\n",
    "    trends_dict[key] = fading_ensembles\n",
    "## Add in NaN values for days that are missing for mc03\n",
    "trends_dict['mc03'][5] = np.nan\n",
    "trends_dict['mc03'][6] = np.nan\n",
    "trends_dict['mc03'].append(0.0) ## value for proportion of fading ensembles on Reversal4\n",
    "trends_dict['mc03'].append(0.0) ## value for proportion of fading ensembles on Training_Reversal\n",
    "## Plot values for each mouse\n",
    "fig = go.Figure()\n",
    "x_axis = session_list\n",
    "for key in trends_dict:\n",
    "    fig.add_trace(go.Scatter(x = x_axis, y = trends_dict[key], name = key))\n",
    "fig.update_layout(template = 'simple_white', height = 500, width = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Fading Ensemble Proportion Across Sessions',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(title = 'Proportion Fading Ensembles')\n",
    "fig.show()\n",
    "fig.write_image(pjoin(figure_path, 'all_sessions_trials.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlate correct rejection rate with proportion of fading ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set relative path variable for circletrack behavior data\n",
    "path = pjoin(behavior_path, 'Data/**/**/**/circle_track.csv')\n",
    "## Set str2match variable (regex for mouse name)\n",
    "str2match = '(mc[0-9]+)'\n",
    "## Create list of files\n",
    "file_list = ctb.get_file_list(path)\n",
    "## Loop through file_list to extract mouse name\n",
    "mouseID = []\n",
    "for file in file_list:\n",
    "    mouse = ctb.get_mouse(file, str2match)\n",
    "    mouseID.append(mouse)\n",
    "## Combine file_list and mouseID\n",
    "combined_list = ctb.combine(file_list, mouseID)\n",
    "## dprime across all mice and all sessions\n",
    "mouse_list = ['mc03', 'mc06', 'mc07', 'mc09', 'mc11']\n",
    "bin_size = 1\n",
    "mouse_signal_data = {}\n",
    "mouse_agg_data = {}\n",
    "mouse_signal_forward = {}\n",
    "mouse_agg_forward = {}\n",
    "mouse_trial_times = {}\n",
    "for mouse in mouse_list:\n",
    "    files = ctb.subset_combined(combined_list, mouse)\n",
    "    signal_dict_all = {}\n",
    "    signal_dict_forward = {}\n",
    "    agg_dict_all = {}\n",
    "    agg_dict_forward = {}\n",
    "    trial_length_session = {}\n",
    "    for path in files:\n",
    "        ## Extract date\n",
    "        date = re.search('(2022_[0-9]+_[0-9]+)', path).group()\n",
    "        ## Load circle track data\n",
    "        circle_track = pd.read_csv(path)\n",
    "        ## Get which ports are the reward ports\n",
    "        reward_one, reward_two = ctb.get_rewarding_ports(circle_track)\n",
    "        ## Normalize timestamps and crop data\n",
    "        circle_track = ctb.normalize_timestamp(circle_track)\n",
    "        circle_track = ctb.crop_data(circle_track)\n",
    "        ## Align behavior data\n",
    "        aligned_behavior = ctb.load_and_align_behavior(behavior_path, mouse, date, session = '30min', plot_frame_usage = False)\n",
    "        ## Get timestamps where mouse licked (replaces REWARD with LICK)\n",
    "        lick_tmp = ctb.get_licks(circle_track)\n",
    "        ## Calculate trials, label each frame as a specific trial\n",
    "        trials = ctb.get_trials(aligned_behavior, shift_factor = 0, angle_type = 'radians', counterclockwise = True)\n",
    "        ## Calculate forward and reverse trials\n",
    "        forward_trials, reverse_trials = ctb.forward_reverse_trials(aligned_behavior, trials, positive_jump = 350, wiggle = 3)\n",
    "        ## Label each frame in aligned_behavior with a trial\n",
    "        aligned_behavior.insert(1, 'trial', trials)\n",
    "        ## Calculate trial times\n",
    "        trial_length_dict = ctb.calculate_trial_times(aligned_behavior, forward_trials)\n",
    "        ## Label lick data with what trial those licks occurred during\n",
    "        lick_data = ctb.label_lick_trials(aligned_behavior, lick_tmp, trials)\n",
    "        ## Calculate dprime, CR, FA, hits, misses for each trial\n",
    "        signal_all = ctb.dprime_metrics(lick_data, trials, reward_one, reward_two)\n",
    "        ## Calculate for only trials in the correct direction\n",
    "        signal_forward = ctb.dprime_metrics(lick_data, forward_trials, reward_one, reward_two, reward_index = 'one')\n",
    "        ## Aggregate data every 5 trials\n",
    "        agg_data = ctb.aggregate_metrics(signal_all, bin_size = bin_size)\n",
    "        ## Aggregate data over forward trials\n",
    "        agg_data_forward = ctb.aggregate_metrics(signal_forward, bin_size = bin_size)\n",
    "        ## Append to dictionaries\n",
    "        signal_dict_all[date] = signal_all\n",
    "        signal_dict_forward[date] = signal_forward\n",
    "        agg_dict_all[date] = agg_data\n",
    "        agg_dict_forward[date] = agg_data_forward\n",
    "        trial_length_session[date] = trial_length_dict\n",
    "    ## Append to mouse dictionaries\n",
    "    mouse_signal_data[mouse] = signal_dict_all\n",
    "    mouse_signal_forward[mouse] = signal_dict_forward\n",
    "    mouse_agg_data[mouse] = agg_dict_all\n",
    "    mouse_agg_forward[mouse] = mouse_agg_forward\n",
    "    mouse_trial_times[mouse] = trial_length_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a scatter plot of trial length vs dprime\n",
    "mouse_df = pd.DataFrame()\n",
    "for mouse in mouse_list:\n",
    "    combined_df = pd.DataFrame()\n",
    "    for date in mouse_signal_forward[mouse]:\n",
    "        df_trials = pd.DataFrame(mouse_trial_times[mouse][date])\n",
    "        df_signal = pd.DataFrame(mouse_signal_forward[mouse][date])\n",
    "        combined_df = pd.concat([df_trials, df_signal], axis = 1)\n",
    "        combined_df.insert(7, 'mouse', mouse)\n",
    "        combined_df.insert(8, 'session', date)\n",
    "        mouse_df = pd.concat([mouse_df, combined_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pf.custom_graph_template('', x_title = \"Trial d'\", y_title = \"Trial Length (s)\")\n",
    "fig.add_trace(go.Scatter(x = mouse_df['dprime'], y = mouse_df['trial_length'], mode = 'markers'))\n",
    "fig.show()\n",
    "fig.write_image(pjoin(figure_path, 'dprime_vs_triallength_cohort1.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Correct Rejection Rate values across all sessions\n",
    "mouse_cr = {}\n",
    "for mouse in mouse_signal_forward:\n",
    "    cr_values = {}\n",
    "    for date in mouse_signal_forward[mouse]:\n",
    "        cr_values[date] = np.nanmean(mouse_signal_forward[mouse][date]['CR'])\n",
    "    mouse_cr[mouse] = cr_values\n",
    "## For mc03, the dates are in a strange order, so reorder the keys\n",
    "desired_ordered_list = ['2022_09_29', '2022_09_30', '2022_10_01', '2022_10_02', '2022_10_03', '2022_10_04', '2022_10_06', '2022_10_07']\n",
    "mouse_cr['mc03'] = {k: mouse_cr['mc03'][k] for k in desired_ordered_list}\n",
    "## Turn into a dataframe\n",
    "cr_df = pd.DataFrame()\n",
    "for i, mouse in enumerate(mouse_cr):\n",
    "    data = pd.DataFrame(mouse_cr[mouse], index = [i])\n",
    "    cr_df = pd.concat([cr_df, data])\n",
    "## Reorder columns\n",
    "columns = ['2022_09_29', '2022_09_30', '2022_10_01', '2022_10_02', '2022_10_03', '2022_10_04', '2022_10_05', '2022_10_06', '2022_10_07']\n",
    "cr_df = cr_df[columns]\n",
    "## Rename columns\n",
    "cr_df = cr_df.rename(columns = {'2022_09_29': 'Training1', '2022_09_30': 'Training2', '2022_10_01': 'Training3', '2022_10_02': 'Training4', \n",
    "                                '2022_10_03': 'Reversal1', '2022_10_04': 'Reversal2', '2022_10_05': 'Reversal3', '2022_10_06': 'Reversal4', '2022_10_07': 'Training_Reversal'})\n",
    "## Insert mice into df\n",
    "cr_df.insert(0, 'mouse', mouse_list)\n",
    "## Rename columns proportion fading ensembles df to insert into cr_df\n",
    "prop_df_fading = prop_df.rename(columns = {'Training4': 'Training4_Fading', 'Reversal1': 'Reversal1_Fading'})\n",
    "## Insert proportion of fading ensembles on Training4 and Reversal1 into df\n",
    "cr_df.insert(10, 'Training4_Fading', prop_df_fading['Training4_Fading'])\n",
    "cr_df.insert(11, 'Reversal1_Fading', prop_df_fading['Reversal1_Fading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression\n",
    "lm_cr_prop = pg.linear_regression(cr_df['Reversal1_Fading'], cr_df['Reversal1'], as_dataframe = False)\n",
    "## Make plot\n",
    "fig = pf.custom_graph_template(title = '', x_title = 'Proportion Fading Ensembles', y_title = 'Peak Correct Rejection Rate')\n",
    "fig.add_trace(go.Scatter(x = cr_df['Reversal1_Fading'], y = cr_df['Reversal1'], mode = 'markers', \n",
    "                         marker_color = 'red', marker = {'line': {'color': 'black', 'width' : 0.25}}, showlegend = False))\n",
    "fig.add_trace(go.Scatter(x = cr_df['Reversal1_Fading'], y = lm_cr_prop['pred'], mode = 'lines', line_color = 'black', showlegend = False))\n",
    "fig.show()\n",
    "fig.write_image(pjoin(figure_path, 'cr_vs_prop_fading_peak.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin activations by FORWARD trials using old behavior data input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set mouse list, across_time, x_bin_size\n",
    "mouse_list = ['mc03', 'mc06', 'mc07', 'mc09', 'mc11'] \n",
    "across_time = False\n",
    "x_bin_size = 15\n",
    "\n",
    "## Create empty dictionaries\n",
    "mouse_trends = {}\n",
    "mouse_binned_activations = {}\n",
    "mouse_slopes = {}\n",
    "mouse_taus = {}\n",
    "## Loop through each mouse\n",
    "for mouse in tqdm(mouse_list):\n",
    "    ## saved ensemble data path\n",
    "    spath = pjoin(ensemble_path, mouse)\n",
    "    ## load in behavior data across all sessions\n",
    "    if not across_time:\n",
    "        mouse_behavior = ctb.import_mouse_behavior_data(behavior_path, mouse, key_file = 'behavior_keys.yml', session = '30min')\n",
    "    ## Create empty dictionaries to store output\n",
    "    determined_trends = {}\n",
    "    binned_activations_dict = {}\n",
    "    slopes_dict = {}\n",
    "    tau_dict = {}\n",
    "    ## Load assemblies\n",
    "    for session in session_dict[mouse]:\n",
    "        ## Load specific session's assemblies\n",
    "        assemblies = ica.load_session_assemblies(mouse, spath = spath, session_id = session)\n",
    "        act = assemblies['activations'].values\n",
    "        ## Load a specific session's behavior data\n",
    "        if not across_time:\n",
    "            aligned_behavior = mouse_behavior[session]\n",
    "            ## Ensure that activations and aligned behavior are the same length\n",
    "            aligned_behavior = ica.align_activations_to_behavior(act, aligned_behavior)\n",
    "            ## Get which timestamps are part of which trial for the aligned behavior data\n",
    "            trials = ctb.get_trials(aligned_behavior, shift_factor = 0, angle_type = 'radians', counterclockwise = True)\n",
    "        if across_time:\n",
    "          trends, binned_activations, slopes, tau = ica.define_ensemble_trends_across_time(act, z_threshold = None, x_bin_size = x_bin_size, analysis_type = 'max', zscored = True, alpha = 'sidak')  \n",
    "        else:\n",
    "            ## Define ensemble trends across trials to determine if activation strength is increasing/decreasing across the session\n",
    "            trends, binned_activations, slopes, tau = ica.define_ensemble_trends_across_trials(act, aligned_behavior, trials, trial_type = 'forward', z_threshold = None, zscored = False)\n",
    "        ## Save to dictionaries\n",
    "        determined_trends[session] = trends\n",
    "        binned_activations_dict[session] = binned_activations\n",
    "        slopes_dict[session] = slopes\n",
    "        tau_dict[session] = tau\n",
    "    ## Determine the proportion of ensembles that are increasing, decreasing, or have no trend based on their activation strength across time\n",
    "    proportion_dict = ica.calculate_proportions_ensembles(determined_trends)\n",
    "    ## Save to mouse dictionaries before looping to the next mouse\n",
    "    mouse_trends[mouse] = proportion_dict\n",
    "    mouse_binned_activations[mouse] = binned_activations_dict\n",
    "    mouse_slopes[mouse] = slopes_dict\n",
    "    mouse_taus[mouse] = tau_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get proportion decreasing values\n",
    "prop_decreasing_T4 = []\n",
    "prop_decreasing_R1 = []\n",
    "mouse_name = []\n",
    "for key in mouse_trends:\n",
    "    prop_decreasing_T4.append(mouse_trends[key]['Training4']['prop_decreasing'])\n",
    "    prop_decreasing_R1.append(mouse_trends[key]['Reversal1']['prop_decreasing'])\n",
    "    mouse_name.append(key)\n",
    "prop_df = pd.DataFrame({'Mouse': mouse_name, 'Training4': prop_decreasing_T4, 'Reversal1': prop_decreasing_R1})\n",
    "## Plot prop_df\n",
    "x = ['Training4', 'Reversal1']\n",
    "avgs = [prop_df.Training4.mean(), prop_df.Reversal1.mean()]\n",
    "sem = [prop_df.Training4.sem(), prop_df.Reversal1.sem()]\n",
    "fig = go.Figure(data = go.Bar(x = x, y = avgs, error_y = dict(type = 'data', array = sem), showlegend = False))\n",
    "for row in prop_df.index:\n",
    "    data = prop_df.loc[row]\n",
    "    fig.add_trace(go.Scatter(x = x, y = [data.Training4, data.Reversal1], mode = 'lines+markers', line_color = 'grey', showlegend = False,\n",
    "                             line = dict(width = 1), name = prop_df.loc[row, 'Mouse'], marker_color = 'grey'))\n",
    "fig.update_layout(template = 'simple_white', width = 500, height = 500)\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'Fading Ensembles by Forward Trials',\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.update_yaxes(title = 'Proportion Fading Ensembles')\n",
    "fig.update_traces(marker_color = 'red', marker_line_color = 'black', marker_line_width = 2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot peak activation of a fading ensemble\n",
    "activations = mouse_binned_activations['mc09']['Reversal1']\n",
    "ensemble_number = 1\n",
    "fig = pf.plot_activation_strength(activations, ensemble_number = ensemble_number, figure_path = figure_path, x_bin_size = None,\n",
    "                                  title = 'Fading Ensemble', y_title = 'Max Z Score', x_title = 'Trials', \n",
    "                                  file_name = 'max_strength_fading_forward_trials.png'.format(x_bin_size), marker_color = 'red')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below was used to detect PCA/ICA ensembles for each mouse and subsequently save those detected ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save assemblies of all sessions in the keys.yml file\n",
    "mouse_list =  ['mc06']    \n",
    "dpath = '/media/caishuman/csstorage3/Austin/CircleTrack/EnsembleRemodeling_Resubmission/circletrack_data'\n",
    "spath = '/media/caishuman/csstorage3/Austin/CircleTrack/EnsembleRemodeling_Resubmission/circletrack_data/assemblies'\n",
    "for mouse in mouse_list:\n",
    "    mpath = pjoin(spath, mouse)\n",
    "    neural_dictionary = ctn.import_mouse_neural_data(dpath, mouse, key_file = 'minian_keys.yml', session = '30min', plot_frame_usage = False)\n",
    "    ica.save_detected_ensembles(mpath, mouse, neural_dictionary, binarize = True, smooth_factor = 5, nullhyp = 'circ', n_shuffles = 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('calcium')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd79809ed5cd61d934147ab957e61d0ca120bfb2ec4541704fc20d5f29e686c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
