{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from os.path import join as pjoin\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import zscore\n",
    "\n",
    "sys.path.append('../')\n",
    "import circletrack_behavior as ctb\n",
    "import circletrack_neural as ctn\n",
    "import place_cells as pc\n",
    "import plotting_functions as pf\n",
    "\n",
    "def training_data_perturbation(sdata, test):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        sdata : xarray.DataArray\n",
    "            Yra or C or S from Minian output\n",
    "        test : str\n",
    "            one of 'Z-Scored', 'Control', 'Roll'\n",
    "    \"\"\"\n",
    "    if test == 'Z-Scored':\n",
    "        ## Normalize data\n",
    "        zdata = xr.apply_ufunc(\n",
    "                zscore,\n",
    "                sdata.chunk({'frame': -1, 'unit_id': -1}),\n",
    "                input_core_dims=[['frame']],\n",
    "                output_core_dims=[['frame']],\n",
    "                kwargs={'axis': 1},\n",
    "                dask='parallelized'\n",
    "        ).compute()\n",
    "    elif test == 'Control':\n",
    "        zdata = sdata.copy()\n",
    "    elif test == 'Roll':\n",
    "        zdata = sdata.copy()\n",
    "    return zdata\n",
    "\n",
    "def testing_data_perturbation(sdata, test):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        sdata : xarray.DataArray\n",
    "            Yra or C or S from Minian output\n",
    "        test : str\n",
    "            one of 'Z-Scored', 'Control', 'Roll'\n",
    "    \"\"\"\n",
    "    if test == 'Z-Scored':\n",
    "        ## Normalize data\n",
    "        zdata = xr.apply_ufunc(\n",
    "                zscore,\n",
    "                sdata.chunk({'frame': -1, 'unit_id': 50}),\n",
    "                input_core_dims=[['frame']],\n",
    "                output_core_dims=[['frame']],\n",
    "                kwargs={'axis': 1},\n",
    "                dask='parallelized'\n",
    "        ).compute()\n",
    "    elif test == 'Control':\n",
    "        zdata = sdata.copy()\n",
    "    elif test == 'Roll':\n",
    "        for neuron in np.arange(0, sdata.shape[0]):\n",
    "            sdata[neuron, :] = np.roll(sdata[neuron, :], shift=np.random.randint(0, sdata.shape[1]))\n",
    "        zdata = sdata.copy()\n",
    "    return zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "project_folder = ['MultiCon_Imaging']\n",
    "experiment_folders = ['MultiCon_Imaging5', 'MultiCon_Imaging6']\n",
    "dpath = f'../../{project_folder[0]}'\n",
    "fig_path = f'../../../Manuscripts/MultiCon/intermediate_plots/decoding'\n",
    "chance_color = '#7d7d7d'\n",
    "avg_color = '#287347'\n",
    "subject_color = '#7d7d7d'\n",
    "ce_colors = ['#7A22BC', '#378616']\n",
    "ce_colors_dict = {'Two-context': '#378616', 'Multi-context': '#7A22BC'}\n",
    "symbol_dict = {'Two-context': 'x', 'Multi-context': 'circle'}\n",
    "symbols_list = ['x', 'circle']\n",
    "context_colors = {'A': '#00802d', 'B': '#006c79', 'C': '#004da4', 'D': '#430073'}\n",
    "mouse_colors = ['midnightblue', 'darkred', 'darkorchid', 'darkturquoise']\n",
    "male_mice = ['mc44', 'mc46', 'mc54', 'mc55']\n",
    "control_mice = ['mc46', 'mc49', 'mc52', 'mc54', 'mc59', 'mc60']\n",
    "experimental_mice = ['mc44', 'mc51', 'mc55', 'mc56', 'mc58']\n",
    "imaging5 = ['mc44', 'mc46', 'mc49', 'mc51', 'mc52']\n",
    "session_list = [f'A{x}' for x in np.arange(1, 6)] + [f'B{x}' for x in np.arange(1, 6)] + [f'C{x}' for x in np.arange(1, 6)] + [f'D{x}' for x in np.arange(1, 6)]\n",
    "control_list = [f'A{x}' for x in np.arange(1, 16)] + [f'B{x}' for x in np.arange(1, 6)]\n",
    "day_list = [f'Day {x}' for x in np.arange(1, 21)]\n",
    "bin_size = 0.2 ## in seconds\n",
    "velocity_thresh = 10\n",
    "centroid_distance = 4\n",
    "data_of_interest = 'aligned_minian' ## one of behav, aligned_minian, aligned_place_cells, lin_behav\n",
    "z_thresh = 1.96\n",
    "folds = 5\n",
    "\n",
    "if not os.path.exists(fig_path):\n",
    "    os.makedirs(fig_path)\n",
    "\n",
    "xr.set_options(keep_attrs=True)\n",
    "\n",
    "np.random.seed(24601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'C'\n",
    "training_sessions_list = [['4', '9'], ['9', '14'], ['14', '19']]\n",
    "testing_sessions_list = [['5', '10'], ['10', '15'], ['15', '20']]\n",
    "context_str_list = ['four_five_ab', 'four_five_bc', 'four_five_cd']\n",
    "correct_dir = True\n",
    "only_running = True\n",
    "output = {'mouse': [], 'comparison': [], 'test': [], 'accuracy': []}\n",
    "\n",
    "for test in ['Control', 'Z-Scored', 'Roll']:\n",
    "    for mouse in experimental_mice:\n",
    "        for idx, training_sessions in enumerate(training_sessions_list):\n",
    "            if mouse == 'mc44':\n",
    "                pass\n",
    "            else:\n",
    "                testing_sessions = testing_sessions_list[idx]\n",
    "                if mouse in imaging5:\n",
    "                    mpath = pjoin(dpath, f'{experiment_folders[0]}/output/aligned_minian/{mouse}/{data_type}')\n",
    "                    crossreg_path = pjoin(dpath, f'{experiment_folders[0]}/output/cross_registration_results')\n",
    "                    file_str = f'mappings_meta_{centroid_distance}_{context_str_list[idx]}.pkl'\n",
    "                else:\n",
    "                    mpath = pjoin(dpath, f'{experiment_folders[1]}/output/aligned_minian/{mouse}/{data_type}')\n",
    "                    crossreg_path = pjoin(dpath, f'{experiment_folders[1]}/output/cross_registration_results')\n",
    "                    file_str = f'mappings_meta_{centroid_distance}_{context_str_list[idx]}.pkl'\n",
    "                mappings = pd.read_pickle(pjoin(crossreg_path, f'circletrack_data/{mouse}/{file_str}'))\n",
    "                mappings.columns = mappings.columns.droplevel(0)\n",
    "\n",
    "                date_list = []\n",
    "                for session in training_sessions + testing_sessions:\n",
    "                    sdata = xr.open_dataset(pjoin(mpath, f'{mouse}_{data_type}_{session}.nc'))[data_type]\n",
    "                    date_list.append(sdata.attrs['date'])\n",
    "                shared_cells = mappings[date_list].dropna().reset_index(drop=True)\n",
    "\n",
    "                \n",
    "                sdata = xr.open_dataset(pjoin(mpath, f'{mouse}_{data_type}_{training_sessions[0]}.nc'))[data_type]\n",
    "                sdata = sdata.sel(unit_id=shared_cells[sdata.attrs['date']].values)\n",
    "                zdata = training_data_perturbation(sdata, test=test)\n",
    "                ndata, _ = ctn.subset_correct_dir_and_running(zdata, correct_dir=correct_dir, \n",
    "                                                              only_running=only_running, velocity_thresh=velocity_thresh)\n",
    "                sub_data = ctn.bin_activity(ndata, bin_size_seconds=bin_size, func=np.mean)\n",
    "                neural_data = sub_data\n",
    "                first_half = sub_data.shape[1]\n",
    "                for session in training_sessions[1:]:\n",
    "                    sdata = xr.open_dataset(pjoin(mpath, f'{mouse}_{data_type}_{session}.nc'))[data_type]\n",
    "                    sdata = sdata.sel(unit_id=shared_cells[sdata.attrs['date']].values)\n",
    "                    zdata = training_data_perturbation(sdata, test=test)\n",
    "                    ndata, _ = ctn.subset_correct_dir_and_running(zdata, correct_dir=correct_dir, \n",
    "                                                                  only_running=only_running, velocity_thresh=velocity_thresh)\n",
    "                    sub_data = ctn.bin_activity(ndata, bin_size_seconds=bin_size, func=np.mean)\n",
    "                    neural_data = np.concatenate([neural_data, sub_data], axis=1)\n",
    "                    second_half = sub_data.shape[1]\n",
    "                neural_data = neural_data.T\n",
    "\n",
    "                if ('4' in training_sessions) & ('9' in training_sessions):\n",
    "                    conditions = np.concatenate([np.repeat(['A'], repeats=first_half), np.repeat(['B'], repeats=second_half)])\n",
    "                    comparison = 'A or B'\n",
    "                elif ('9' in training_sessions) & ('14' in training_sessions):\n",
    "                    conditions = np.concatenate([np.repeat(['B'], repeats=first_half), np.repeat(['C'], repeats=second_half)])\n",
    "                    comparison = 'B or C'\n",
    "                elif ('14' in training_sessions) & ('19' in training_sessions):\n",
    "                    conditions = np.concatenate([np.repeat(['C'], repeats=first_half), np.repeat(['D'], repeats=second_half)])\n",
    "                    comparison = 'C or D'\n",
    "                ## Train decoder using training data from day 4 in specified contexts\n",
    "                clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=24601)\n",
    "                X_train = neural_data\n",
    "                y_train = conditions\n",
    "                clf.fit(X_train, y_train)\n",
    "\n",
    "                ## Get testing sessions (day 5 of specified contexts)\n",
    "                sdata = xr.open_dataset(pjoin(mpath, f'{mouse}_{data_type}_{testing_sessions[0]}.nc'))[data_type]\n",
    "                sdata = sdata.sel(unit_id=shared_cells[sdata.attrs['date']].values)\n",
    "                zdata = testing_data_perturbation(sdata, test=test)\n",
    "                ndata, _ = ctn.subset_correct_dir_and_running(zdata, correct_dir=correct_dir, \n",
    "                                                              only_running=only_running, velocity_thresh=velocity_thresh)\n",
    "                sub_data = ctn.bin_activity(ndata, bin_size_seconds=bin_size, func=np.mean)\n",
    "                X_test = sub_data\n",
    "                first_half = sub_data.shape[1]\n",
    "                for session in testing_sessions[1:]:\n",
    "                    sdata = xr.open_dataset(pjoin(mpath, f'{mouse}_{data_type}_{session}.nc'))[data_type]\n",
    "                    sdata = sdata.sel(unit_id=shared_cells[sdata.attrs['date']].values)\n",
    "                    zdata = testing_data_perturbation(sdata, test=test)\n",
    "                    ndata, position_data = ctn.subset_correct_dir_and_running(zdata, correct_dir=correct_dir, \n",
    "                                                                              only_running=only_running, velocity_thresh=velocity_thresh)\n",
    "                    sub_data = ctn.bin_activity(ndata, bin_size_seconds=bin_size, func=np.mean)\n",
    "                    X_test = np.concatenate([X_test, sub_data], axis=1)\n",
    "                    second_half = sub_data.shape[1]\n",
    "                X_test = X_test.T\n",
    "                if ('4' in training_sessions) & ('9' in training_sessions):\n",
    "                    y_test = np.concatenate([np.repeat(['A'], repeats=first_half), np.repeat(['B'], repeats=second_half)])\n",
    "                elif ('9' in training_sessions) & ('14' in training_sessions):\n",
    "                    y_test = np.concatenate([np.repeat(['B'], repeats=first_half), np.repeat(['C'], repeats=second_half)])\n",
    "                elif ('14' in training_sessions) & ('19' in training_sessions):\n",
    "                    y_test = np.concatenate([np.repeat(['C'], repeats=first_half), np.repeat(['D'], repeats=second_half)])\n",
    "\n",
    "                ## Create predictions using trained random forest\n",
    "                preds = clf.predict(X_test)\n",
    "\n",
    "                ## Accuracy\n",
    "                overall_acc = np.mean(preds == y_test)\n",
    "                chance = 1 / len(np.unique(conditions))\n",
    "\n",
    "                ## Save results\n",
    "                output['mouse'].append(mouse)\n",
    "                output['comparison'].append(comparison)\n",
    "                output['test'].append(test)\n",
    "                output['accuracy'].append(overall_acc)\n",
    "acc_df = pd.DataFrame(output)\n",
    "avg_acc = acc_df.groupby(['comparison', 'test'], as_index=False).agg({'accuracy': ['mean', 'sem']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot accuracies for all mice using non-normalized cell data\n",
    "add_mice = True\n",
    "normal = avg_acc[avg_acc['test'] == 'Control']\n",
    "fig = pf.custom_graph_template(x_title='', y_title='Decoding Accuracy')\n",
    "fig.add_trace(go.Scatter(x=normal['comparison'], y=normal['accuracy']['mean'], mode='markers', marker_color='darkgrey',\n",
    "                         error_y=dict(type='data', array=normal['accuracy']['sem']), showlegend=False))\n",
    "if add_mice:\n",
    "    for mouse in experimental_mice:\n",
    "        mdata = acc_df[(acc_df['mouse'] == mouse) & (acc_df['test'] == 'Control')].reset_index(drop=True)\n",
    "        if mouse in male_mice:\n",
    "            color = 'midnightblue'\n",
    "        else:\n",
    "            color = 'darkorchid'\n",
    "        fig.add_trace(go.Scatter(x=mdata['comparison'], y=mdata['accuracy'], mode='lines', line_color=color, \n",
    "                                 line_width=1, opacity=0.7, name=mouse, showlegend=False))\n",
    "fig.add_hline(y=chance, line_width=1, line_color=chance_color, line_dash='dash', opacity=1)\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.show()\n",
    "# fig.write_image(pjoin(fig_path, 'decision_tree_aorb_borc_cord.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot accuracies for all mice with the different tests\n",
    "add_mice = True\n",
    "fig = pf.custom_graph_template(x_title='', y_title='', titles=['A or B', 'B or C', 'C or D'], \n",
    "                               rows=1, columns=3, shared_y=True, width=1200)\n",
    "for idx, cmp in enumerate(['A or B', 'B or C', 'C or D']):\n",
    "    data = avg_acc[avg_acc['comparison'] == cmp]\n",
    "    fig.add_trace(go.Scatter(x=data['test'], y=data['accuracy']['mean'], mode='markers', marker_color=avg_color,\n",
    "                             error_y=dict(type='data', array=data['accuracy']['sem']), showlegend=False), row=1, col=idx+1)\n",
    "if add_mice:\n",
    "    for mouse in experimental_mice:\n",
    "        for idx, cmp in enumerate(['A or B', 'B or C', 'C or D']):\n",
    "            mdata = acc_df[(acc_df['mouse'] == mouse) & (acc_df['comparison'] == cmp)].reset_index(drop=True)\n",
    "            mdata = mdata.reindex(index=[0, 2, 1])\n",
    "            fig.add_trace(go.Scatter(x=mdata['test'], y=mdata['accuracy'], mode='lines', line_color=avg_color, \n",
    "                                    line_width=1, opacity=0.7, name=mouse, showlegend=False), row=1, col=idx+1)\n",
    "fig.update_yaxes(title='Decoding Accuracy', col=1)\n",
    "fig.update_yaxes(range=[0, 1.05])\n",
    "fig.add_hline(y=chance, line_width=1, line_color=chance_color, line_dash='dash', opacity=1)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calcium_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
